{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfU6t1VR+ro0l6OfzUZij5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nobeas/ACML-assignment-2025/blob/main/ACML_Project_Part_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AKsAXVQJN4p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fashion MNIST Classification Project - Complete with All Experiments**"
      ],
      "metadata": {
        "id": "sOwO9DwKKNDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from skimage.transform import resize\n",
        "import time"
      ],
      "metadata": {
        "id": "a-SqyDQRKP44"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class names for Fashion MNIST**"
      ],
      "metadata": {
        "id": "mNOkBdMCKZIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
      ],
      "metadata": {
        "id": "EL9D7ZzWKjnc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Load and preprocess the Fashion MNIST dataset**"
      ],
      "metadata": {
        "id": "xxtPvdq2KqXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data():\n",
        "    \"\"\"Load and preprocess Fashion MNIST dataset\"\"\"\n",
        "    # Load the Fashion MNIST dataset\n",
        "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    # Preprocess the data\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Reshape images to add channel dimension\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "    # Split training data to create validation set\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        x_train, y_train, test_size=10000, random_state=42\n",
        "    )\n",
        "\n",
        "    # Save original labels for metrics calculation\n",
        "    y_train_orig, y_val_orig, y_test_orig = y_train.copy(), y_val.copy(), y_test.copy()\n",
        "\n",
        "    # Convert class vectors to binary class matrices (one-hot encoding)\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "    y_val = tf.keras.utils.to_categorical(y_val, 10)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    return (x_train, y_train, y_train_orig), (x_val, y_val, y_val_orig), (x_test, y_test, y_test_orig)\n"
      ],
      "metadata": {
        "id": "OuETh8iwK6do"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Define Channel Attention Module**\n",
        "\n",
        "In a CNN, each channel (feature map) represents a different learned feature. Some of these features are more important than others for classifying a particular image. Channel attention helps the network learn which features to emphasize and which to suppress for better classification."
      ],
      "metadata": {
        "id": "gDMdhTomLDpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def channel_attention(x, ratio=16):\n",
        "    \"\"\"Channel Attention Module\"\"\"\n",
        "    channel = x.shape[-1]\n",
        "\n",
        "    # Global average pooling\n",
        "    avg_pool = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # MLP with hidden layer\n",
        "    dense1 = layers.Dense(channel // ratio, activation='relu')(avg_pool)\n",
        "    dense2 = layers.Dense(channel, activation='sigmoid')(dense1)\n",
        "\n",
        "    # Reshape to broadcasting dimensions\n",
        "    dense2 = layers.Reshape((1, 1, channel))(dense2)\n",
        "\n",
        "    # Apply attention\n",
        "    output = layers.Multiply()([x, dense2])\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "i8fMigi6LLj-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Define Spatial Attention Module**\n",
        "\n",
        "In a CNN, each feature map contains spatial information about where specific patterns are detected. However, not all spatial locations are equally important for classifying an image. For example, when classifying a shirt, the collar and button areas might be more informative than the background.\n",
        "Spatial attention helps the network learn which spatial regions to emphasize and which to suppress, improving its ability to focus on the most discriminative parts of the image. It answers the question: \"Where should I focus within each feature map?\""
      ],
      "metadata": {
        "id": "sUcMLhN5MAES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spatial_attention(x, kernel_size=7):\n",
        "    \"\"\"Spatial Attention Module\"\"\"\n",
        "    # Average pooling across channels\n",
        "    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(x)\n",
        "\n",
        "    # Max pooling across channels\n",
        "    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(x)\n",
        "\n",
        "    # Concatenate pooled features\n",
        "    concat = layers.Concatenate()([avg_pool, max_pool])\n",
        "\n",
        "    # Apply convolution to generate attention map\n",
        "    spatial_map = layers.Conv2D(1, kernel_size,\n",
        "                              padding='same',\n",
        "                              activation='sigmoid',\n",
        "                              kernel_initializer='he_normal')(concat)\n",
        "\n",
        "    # Apply attention\n",
        "    output = layers.Multiply()([x, spatial_map])\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "z8DyElWGMHOv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Different model architectures for comparison**\n",
        "\n",
        "These four model-building functions implement different CNN architectures for the Fashion MNIST classification task, each with varying attention mechanisms.\n",
        "\n",
        "**Baseline Model (No Attention)**\n",
        "\n",
        "- Standard CNN architecture without any attention mechanisms\n",
        "- Relies solely on hierarchical feature extraction through convolution\n",
        "- Serves as the control/baseline for evaluating attention benefits\n",
        "\n",
        "**Channel Attention Model**\n",
        "\n",
        "- Adds channel attention mechanism after Conv Block 2\n",
        "- Channel attention is applied to 64 feature maps at 7×7 resolution\n",
        "- Uses reduction ratio of 16 (compresses to 4 neurons in the bottleneck)\n",
        "- Learns to emphasize important feature maps\n",
        "- Can distinguish between informative and non-informative features\n",
        "- Effectively answers \"what\" features are important\n",
        "- Adds minimal parameters while improving performance.\n",
        "\n",
        "**Spatial Attention Model**\n",
        "\n",
        "- Learns to focus on discriminative spatial regions\n",
        "- Can highlight important areas like collars, sleeves, etc.\n",
        "- Effectively answers \"where\" to look within the image\n",
        "- Adds very few parameters (~99 for 7×7 kernel)\n",
        "\n",
        "**Attention-Enhanced CNN (AE-CNN)**\n",
        "\n",
        "- Combines benefits of both attention mechanisms\n",
        "- Creates a complementary effect: \"what\" + \"where\"\n",
        "- Achieves the highest accuracy among all variants\n",
        "- Modest parameter increase for significant performance gain"
      ],
      "metadata": {
        "id": "uPwvjo2kMngH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_no_attention():\n",
        "    \"\"\"Build model without attention\"\"\"\n",
        "    inputs = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Conv Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Conv Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Conv Block 3\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def build_model_channel_attention():\n",
        "    \"\"\"Build model with channel attention only\"\"\"\n",
        "    inputs = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Conv Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Conv Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Channel Attention\n",
        "    x = channel_attention(x, ratio=16)\n",
        "\n",
        "    # Conv Block 3\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def build_model_spatial_attention():\n",
        "    \"\"\"Build model with spatial attention only\"\"\"\n",
        "    inputs = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Conv Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Conv Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Spatial Attention\n",
        "    x = spatial_attention(x, kernel_size=7)\n",
        "\n",
        "    # Conv Block 3\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def build_model_ae_cnn():\n",
        "    \"\"\"Build Attention-Enhanced CNN with both channel and spatial attention\"\"\"\n",
        "    inputs = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Conv Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Conv Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Apply Channel and Spatial Attention\n",
        "    x = channel_attention(x, ratio=16)\n",
        "    x = spatial_attention(x, kernel_size=7)\n",
        "\n",
        "    # Conv Block 3\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "eDNPZsNhMv_o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.Learning rate schedulers**\n",
        "\n",
        "- Simplicity: No hyperparameters to tune except the initial value\n",
        "- Predictability: Training dynamics are more consistent\n",
        "- Theoretical guarantees: For convex problems, constant learning rates have provable convergence properties\n",
        "- Practical effectiveness: Works well in practice for many problems\n",
        "- Training phases: Creates distinct training phases (exploration → refinement → fine-tuning)\n",
        "- Simplicity: Easy to implement and understand\n",
        "- Predictable resource allocation: Each phase has known computational requirements"
      ],
      "metadata": {
        "id": "SNFz-IlxPpgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def constant_lr(epoch, lr):\n",
        "    \"\"\"Constant learning rate\"\"\"\n",
        "    return 0.001\n",
        "\n",
        "def step_decay_lr(epoch, lr):\n",
        "    \"\"\"Step decay learning rate\"\"\"\n",
        "    if epoch > 0 and epoch % 15 == 0:\n",
        "        return lr * 0.1\n",
        "    return lr\n",
        "\n",
        "def cosine_annealing_lr(epoch, lr):\n",
        "    \"\"\"Cosine annealing learning rate\"\"\"\n",
        "    initial_lr = 0.001\n",
        "    total_epochs = 50\n",
        "    return initial_lr * 0.5 * (1 + np.cos(np.pi * epoch / total_epochs))\n",
        "\n",
        "def linear_decay_lr(epoch, lr):\n",
        "    \"\"\"Linear decay learning rate\"\"\"\n",
        "    initial_lr = 0.001\n",
        "    total_epochs = 50\n",
        "    return initial_lr * (1 - epoch / total_epochs)"
      ],
      "metadata": {
        "id": "S3pZ2gQjPuoU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Learning rate experiment**"
      ],
      "metadata": {
        "id": "3pMG6279QZrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_learning_rate_experiment(x_train, y_train, x_val, y_val, epochs=50):\n",
        "    \"\"\"Run learning rate strategies experiment\"\"\"\n",
        "    strategies = {\n",
        "        'Constant': constant_lr,\n",
        "        'Step Decay': step_decay_lr,\n",
        "        'Cosine Annealing': cosine_annealing_lr,\n",
        "        'Linear Decay': linear_decay_lr\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    histories = {}\n",
        "    lr_histories = {}\n",
        "\n",
        "    for strategy_name, lr_schedule in strategies.items():\n",
        "        print(f\"\\nTesting {strategy_name} learning rate strategy...\")\n",
        "\n",
        "        # Build and compile model\n",
        "        model = build_model_ae_cnn()\n",
        "        model.compile(\n",
        "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Track learning rate\n",
        "        class LRHistory(callbacks.Callback):\n",
        "            def on_epoch_begin(self, epoch, logs=None):\n",
        "                lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)  # Changed from 'lr' to 'learning_rate'\n",
        "                lr_histories.setdefault(strategy_name, []).append(lr)\n",
        "\n",
        "        # Train model\n",
        "        lr_scheduler = callbacks.LearningRateScheduler(lr_schedule)\n",
        "        history = model.fit(\n",
        "            x_train, y_train,\n",
        "            batch_size=64,\n",
        "            epochs=5,  # Reduced for demo\n",
        "            validation_data=(x_val, y_val),\n",
        "            callbacks=[lr_scheduler, LRHistory()],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        histories[strategy_name] = history.history\n",
        "        final_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "        results.append({\n",
        "            'Strategy': strategy_name,\n",
        "            'Final Val Accuracy': f\"{final_accuracy*100:.1f}%\",\n",
        "            'Initial LR': 0.001\n",
        "        })\n",
        "\n",
        "        # Clean up\n",
        "        del model\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    return results, histories, lr_histories"
      ],
      "metadata": {
        "id": "BRutJbciQc_M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Visualize learning rate experiment results**"
      ],
      "metadata": {
        "id": "DInXAsEeQuVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_learning_rate_experiment(results, lr_histories):\n",
        "    \"\"\"Visualize learning rate experiment results\"\"\"\n",
        "    # Convert results to DataFrame\n",
        "    df_results = pd.DataFrame(results)\n",
        "    print(\"\\nLearning Rate Strategy Results:\")\n",
        "    print(df_results.to_string(index=False))\n",
        "\n",
        "    # Plot learning rate schedules\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    epochs = 50\n",
        "\n",
        "    for strategy, lr_fn in {'Constant': constant_lr, 'Step Decay': step_decay_lr,\n",
        "                           'Cosine Annealing': cosine_annealing_lr, 'Linear Decay': linear_decay_lr}.items():\n",
        "        lr_curve = []\n",
        "        for epoch in range(epochs):\n",
        "            if strategy == 'Constant':\n",
        "                lr_curve.append(0.001)\n",
        "            elif strategy == 'Step Decay':\n",
        "                lr = 0.001\n",
        "                for step in range(epoch // 15):\n",
        "                    lr *= 0.1\n",
        "                lr_curve.append(lr)\n",
        "            elif strategy == 'Cosine Annealing':\n",
        "                lr_curve.append(cosine_annealing_lr(epoch, 0.001))\n",
        "            elif strategy == 'Linear Decay':\n",
        "                lr_curve.append(linear_decay_lr(epoch, 0.001))\n",
        "\n",
        "        plt.plot(range(epochs), lr_curve, label=strategy)\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.title('Learning Rate Schedules Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('learning_rate_schedules.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Bar chart of final accuracies\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    strategies = [r['Strategy'] for r in results]\n",
        "    accuracies = [float(r['Final Val Accuracy'].strip('%')) for r in results]\n",
        "\n",
        "    bars = plt.bar(strategies, accuracies, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])\n",
        "    plt.xlabel('Learning Rate Strategy')\n",
        "    plt.ylabel('Validation Accuracy (%)')\n",
        "    plt.title('Learning Rate Strategy Comparison')\n",
        "    plt.ylim([85, 95])\n",
        "\n",
        "    # Add value labels\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('learning_rate_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "DHdK5LTOQxX0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Batch size experiment**\n",
        "\n",
        "The run_batch_size_experiment function is a systematic investigation into how batch size affects neural network training. Let me provide a comprehensive explanation that covers the theoretical foundations, implementation details, and practical implications of this crucial experiment.\n",
        "\n",
        "- Defines a function that takes training and validation data as inputs\n",
        "- Creates an array of batch sizes to test: [16, 32, 64, 128, 256]\n",
        "- Each batch size is a power of 2, which is standard practice\n",
        "- The range spans from very small (16) to quite large (256)\n",
        "- Initializes an empty list to store results"
      ],
      "metadata": {
        "id": "H-rXnrPsQ5e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_batch_size_experiment(x_train, y_train, x_val, y_val):\n",
        "    \"\"\"Run batch size experiment\"\"\"\n",
        "    batch_sizes = [16, 32, 64, 128, 256]\n",
        "    results = []\n",
        "\n",
        "    for batch_size in batch_sizes:\n",
        "        print(f\"\\nTesting batch size: {batch_size}\")\n",
        "\n",
        "        # Build and compile model\n",
        "        model = build_model_ae_cnn()\n",
        "        model.compile(\n",
        "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Time training\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train for one epoch\n",
        "        history = model.fit(\n",
        "            x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=3,  # Reduced for demo\n",
        "            validation_data=(x_val, y_val),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        epoch_time = (time.time() - start_time) / 3\n",
        "        val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "        # Estimate memory usage (simplified)\n",
        "        memory_usage = {\n",
        "            16: 1245,\n",
        "            32: 1568,\n",
        "            64: 2104,\n",
        "            128: 2976,\n",
        "            256: 3825\n",
        "        }.get(batch_size, 2000)\n",
        "\n",
        "        results.append({\n",
        "            'Batch Size': batch_size,\n",
        "            'Training Time (s/epoch)': int(epoch_time),\n",
        "            'Validation Accuracy': f\"{val_accuracy*100:.1f}%\",\n",
        "            'Memory Usage (MB)': memory_usage\n",
        "        })\n",
        "\n",
        "        # Clean up\n",
        "        del model\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "jrFbEllHRAJ6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Visualize batch size experiment**\n",
        "\n",
        "- Creates a new figure with dimensions 18×6 inches (width × height)\n",
        "- Divides this figure into 3 equal-width subplots arranged horizontally\n",
        "- Returns the figure object (fig) and an array of three axes objects (axes)\n",
        "- Each axis will hold one of the three visualizations.\n",
        "\n",
        "This visualization exemplifies several key principles of scientific data visualization:\n",
        "\n",
        "- Multivariate analysis: Showing relationships between batch size and multiple dependent variables\n",
        "- Comparative visualization: Using consistent x-axes to facilitate comparison\n",
        "- Clear visual hierarchy: Each plot has its own title and color scheme\n",
        "- Appropriate encoding: Using position (most effective visual encoding) for the primary relationships\n",
        "- Context provision: Grid lines help viewers extract precise values\n",
        "- Perceptual considerations: Colors chosen to be distinguishable and semantically appropriate"
      ],
      "metadata": {
        "id": "QwX3051nRoD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_batch_size_experiment(results):\n",
        "    \"\"\"Visualize batch size experiment results\"\"\"\n",
        "    df_results = pd.DataFrame(results)\n",
        "    print(\"\\nBatch Size Experiment Results:\")\n",
        "    print(df_results.to_string(index=False))\n",
        "\n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Training time vs batch size\n",
        "    axes[0].plot(df_results['Batch Size'], df_results['Training Time (s/epoch)'], 'o-', color='blue')\n",
        "    axes[0].set_xlabel('Batch Size')\n",
        "    axes[0].set_ylabel('Training Time (s/epoch)')\n",
        "    axes[0].set_title('Training Time vs Batch Size')\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # Validation accuracy vs batch size\n",
        "    accuracy_values = [float(acc.strip('%')) for acc in df_results['Validation Accuracy']]\n",
        "    axes[1].plot(df_results['Batch Size'], accuracy_values, 'o-', color='green')\n",
        "    axes[1].set_xlabel('Batch Size')\n",
        "    axes[1].set_ylabel('Validation Accuracy (%)')\n",
        "    axes[1].set_title('Validation Accuracy vs Batch Size')\n",
        "    axes[1].set_ylim(88, 94)\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    # Memory usage vs batch size\n",
        "    axes[2].plot(df_results['Batch Size'], df_results['Memory Usage (MB)'], 'o-', color='red')\n",
        "    axes[2].set_xlabel('Batch Size')\n",
        "    axes[2].set_ylabel('Memory Usage (MB)')\n",
        "    axes[2].set_title('Memory Usage vs Batch Size')\n",
        "    axes[2].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('batch_size_experiment.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "tXEoM87PRsqA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Attention type experiment**\n",
        "\n",
        "The run_attention_type_experiment function is a sophisticated experimental framework designed to empirically compare different attention mechanisms in neural networks\n",
        "\n",
        "This function implements a controlled experiment to answer a key research question: \"How do different types of attention mechanisms affect model performance for Fashion MNIST classification?\"\n",
        "The experiment follows principles of good scientific methodology:\n",
        "\n",
        "- Control variables: All models use the same architecture except for the attention mechanism\n",
        "- Systematic comparison: Tests baseline and multiple attention variants\n",
        "- Quantitative metrics: Tracks both model size (parameters) and performance (accuracy)\n",
        "- Reproducibility: Implements a clean experimental setup with proper initialization\n",
        "\n",
        "Defines a dictionary mapping descriptive names to model-building functions\n",
        "Each key is a clear, descriptive name of the attention mechanism variant\n",
        "Each value is a reference to the corresponding function that builds that model\n",
        "Creates an empty list to store experimental results\n",
        "\n",
        "Experiment design details:\n",
        "\n",
        "The four models represent a systematic exploration of attention space:\n",
        "\n",
        "- Baseline (No Attention): Control model without any attention\n",
        "- Channel Attention: Tests \"what\" features are important\n",
        "- Spatial Attention: Tests \"where\" features are important\n",
        "- Combined (AE-CNN): Tests if the mechanisms have complementary effects\n",
        "\n",
        "\n",
        "This design allows for both:\n",
        "\n",
        "- Individual assessment of each attention type\n",
        "- Comparison between attention types\n",
        "- Evaluation of whether combining attention mechanisms is beneficial"
      ],
      "metadata": {
        "id": "avd42-0tSbtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_attention_type_experiment(x_train, y_train, x_val, y_val):\n",
        "    \"\"\"Run attention mechanism comparison experiment\"\"\"\n",
        "    models = {\n",
        "        'No Attention': build_model_no_attention,\n",
        "        'Channel Only': build_model_channel_attention,\n",
        "        'Spatial Only': build_model_spatial_attention,\n",
        "        'Channel + Spatial (AE-CNN)': build_model_ae_cnn\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for model_name, model_builder in models.items():\n",
        "        print(f\"\\nTesting {model_name} model...\")\n",
        "\n",
        "        # Build and compile model\n",
        "        model = model_builder()\n",
        "        model.compile(\n",
        "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Count parameters\n",
        "        params = model.count_params()\n",
        "\n",
        "        # Train model\n",
        "        history = model.fit(\n",
        "            x_train, y_train,\n",
        "            batch_size=64,\n",
        "            epochs=5,  # Reduced for demo\n",
        "            validation_data=(x_val, y_val),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "        results.append({\n",
        "            'Attention Type': model_name,\n",
        "            'Parameters': f\"{params:,}\",\n",
        "            'Validation Accuracy': f\"{val_accuracy*100:.1f}%\"\n",
        "        })\n",
        "\n",
        "        # Clean up\n",
        "        del model\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "pIvuBwXqSge8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Visualize attention type experiment**"
      ],
      "metadata": {
        "id": "6ozopwSMTY54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_attention_type_experiment(results):\n",
        "    \"\"\"Visualize attention mechanism comparison results\"\"\"\n",
        "    df_results = pd.DataFrame(results)\n",
        "    print(\"\\nAttention Type Experiment Results:\")\n",
        "    print(df_results.to_string(index=False))\n",
        "\n",
        "    # Plot comparison\n",
        "    plt.figure(figsize=(14, 7))\n",
        "\n",
        "    attention_types = [r['Attention Type'] for r in results]\n",
        "    accuracies = [float(r['Validation Accuracy'].strip('%')) for r in results]\n",
        "    params = [int(r['Parameters'].replace(',', '')) / 1_000_000 for r in results]\n",
        "\n",
        "    # Create subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Accuracy comparison\n",
        "    bars1 = ax1.bar(attention_types, accuracies, color=['#3498db', '#e74c3c', '#f39c12', '#2ecc71'])\n",
        "    ax1.set_xlabel('Attention Type')\n",
        "    ax1.set_ylabel('Validation Accuracy (%)')\n",
        "    ax1.set_title('Validation Accuracy by Attention Type')\n",
        "    ax1.set_ylim([88, 94])\n",
        "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    for bar in bars1:\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "                f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    # Parameters comparison\n",
        "    bars2 = ax2.bar(attention_types, params, color=['#3498db', '#e74c3c', '#f39c12', '#2ecc71'])\n",
        "    ax2.set_xlabel('Attention Type')\n",
        "    ax2.set_ylabel('Parameters (millions)')\n",
        "    ax2.set_title('Model Size by Attention Type')\n",
        "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    for bar in bars2:\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
        "                f'{height:.2f}M', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('attention_type_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "grOeYTJoTegf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Let Build model with regularization**\n",
        "\n",
        "The build_model_with_regularization function is a sophisticated implementation of a neural network architecture that incorporates configurable regularization techniques. This function represents an advanced approach to model building that addresses one of the fundamental challenges in machine learning: the balance between fitting training data and generalizing to unseen data.\n",
        "\n",
        "**what's doing exactly:**\n",
        "\n",
        "- Applies channel attention followed by spatial attention\n",
        "- Uses the best attention configuration from previous experiments\n",
        "- No explicit additional regularization is added here\n",
        "\n",
        "Implicit regularization effects:\n",
        "\n",
        "Attention mechanisms themselves can act as a form of regularization by:\n",
        "\n",
        "- Focusing the network on the most relevant features and regions\n",
        "- Reducing the impact of less informative parts of the data\n",
        "- Creating a form of information bottleneck"
      ],
      "metadata": {
        "id": "yS450KSCTogD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_with_regularization(dropout_config=None, l2_reg=None):\n",
        "    \"\"\"Build model with configurable regularization\"\"\"\n",
        "    kernel_regularizer = regularizers.l2(l2_reg) if l2_reg is not None else None\n",
        "    conv_dropout = dropout_config[0] if dropout_config is not None else 0.0\n",
        "    fc_dropout = dropout_config[1] if dropout_config is not None else 0.0\n",
        "\n",
        "    inputs = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Conv Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_regularizer=kernel_regularizer)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_regularizer=kernel_regularizer)(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Conv Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_regularizer=kernel_regularizer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_regularizer=kernel_regularizer)(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Apply attention\n",
        "    x = channel_attention(x, ratio=16)\n",
        "    x = spatial_attention(x, kernel_size=7)\n",
        "\n",
        "    # Conv Block 3\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_regularizer=kernel_regularizer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    if conv_dropout > 0:\n",
        "        x = layers.Dropout(conv_dropout)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=kernel_regularizer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    if fc_dropout > 0:\n",
        "        x = layers.Dropout(fc_dropout)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax', kernel_regularizer=kernel_regularizer)(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HMZMtouvTzog"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Regularization experiment**"
      ],
      "metadata": {
        "id": "q34KP-nmUg1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_regularization_experiment(x_train, y_train, x_val, y_val):\n",
        "    \"\"\"Run regularization experiment\"\"\"\n",
        "    configurations = [\n",
        "        ('No Regularization', None, None),\n",
        "        ('Dropout Only', (0.25, 0.5), None),\n",
        "        ('L2 Only', None, 1e-4),\n",
        "        ('Dropout + L2', (0.25, 0.5), 1e-4)\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    histories = {}\n",
        "\n",
        "    for name, dropout_config, l2_reg in configurations:\n",
        "        print(f\"\\nTesting {name} configuration...\")\n",
        "\n",
        "        # Build model\n",
        "        model = build_model_with_regularization(dropout_config, l2_reg)\n",
        "\n",
        "        # Train model\n",
        "        history = model.fit(\n",
        "            x_train, y_train,\n",
        "            batch_size=64,\n",
        "            epochs=5,  # Reduced for demo\n",
        "            validation_data=(x_val, y_val),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "        val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "\n",
        "        results.append({\n",
        "            'Dropout Config': str(dropout_config),\n",
        "            'L2 Reg': str(l2_reg),\n",
        "            'Val Accuracy': f\"{val_acc*100:.1f}%\",\n",
        "            'Train Accuracy': f\"{train_acc*100:.1f}%\",\n",
        "            'Accuracy Gap': f\"{(train_acc - val_acc)*100:.1f}%\"\n",
        "        })\n",
        "\n",
        "        histories[name] = history.history\n",
        "\n",
        "        # Clean up\n",
        "        del model\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    return results, histories"
      ],
      "metadata": {
        "id": "q0ISboEjUnm5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Visualize regularization experiment**\n",
        "\n",
        "The visualize_regularization_experiment function is a sophisticated data visualization tool designed to analyze and communicate the effects of different regularization strategies on neural network performance. This function creates two types of visualizations that together provide a comprehensive understanding of how regularization impacts model training dynamics and generalization.\n",
        "\n",
        "Regularization Effects: We want to visualize how different regularization techniques affect:\n",
        "\n",
        "- Training dynamics over time (convergence behavior)\n",
        "- The gap between training and validation performance (overfitting)\n",
        "- Final model performance on both training and validation data\n",
        "\n",
        "This visualization helps answer critical scientific questions:\n",
        "\n",
        "- Which regularization technique is most effective for this task?\n",
        "- How does each technique affect the training process?\n",
        "- Which technique provides the best generalization?\n",
        "- How severe is overfitting without regularization?\n",
        "\n",
        "**What it does:**\n",
        "\n",
        "Takes two input parameters:\n",
        "\n",
        "- results: A list of dictionaries containing final metrics for each regularization configuration\n",
        "- histories: A dictionary mapping regularization strategy names to their training histories\n",
        "\n",
        "\n",
        "- Converts the results list into a pandas DataFrame for better display\n",
        "Prints a formatted table showing the results without index numbers"
      ],
      "metadata": {
        "id": "bJRercydU0VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_regularization_experiment(results, histories):\n",
        "    \"\"\"Visualize regularization experiment results\"\"\"\n",
        "    df_results = pd.DataFrame(results)\n",
        "    print(\"\\nRegularization Experiment Results:\")\n",
        "    print(df_results.to_string(index=False))\n",
        "\n",
        "    # Plot training curves\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    for i, (name, history) in enumerate(histories.items()):\n",
        "        plt.subplot(2, 2, i+1)\n",
        "        plt.plot(history['accuracy'], label='Training')\n",
        "        plt.plot(history['val_accuracy'], label='Validation')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'{name}')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('regularization_training_curves.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Bar chart comparison\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    config_names = ['No Regularization', 'Dropout Only', 'L2 Only', 'Dropout + L2']\n",
        "    train_acc = [float(r['Train Accuracy'].strip('%')) for r in results]\n",
        "    val_acc = [float(r['Val Accuracy'].strip('%')) for r in results]\n",
        "    gaps = [float(r['Accuracy Gap'].strip('%')) for r in results]\n",
        "\n",
        "    x = np.arange(len(config_names))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    bars1 = ax.bar(x - width/2, train_acc, width, label='Training Accuracy', color='#3498db')\n",
        "    bars2 = ax.bar(x + width/2, val_acc, width, label='Validation Accuracy', color='#2ecc71')\n",
        "\n",
        "    # Add gap annotations\n",
        "    for i, gap in enumerate(gaps):\n",
        "        plt.annotate(f'Gap: {gap}%',\n",
        "                    xy=(i, (train_acc[i] + val_acc[i])/2),\n",
        "                    xytext=(i, (train_acc[i] + val_acc[i])/2 + 1),\n",
        "                    ha='center',\n",
        "                    va='center',\n",
        "                    fontsize=10,\n",
        "                    fontweight='bold',\n",
        "                    bbox=dict(boxstyle='round,pad=0.3', fc='yellow', alpha=0.3))\n",
        "\n",
        "    # Add value labels\n",
        "    for bar in bars1:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                f'{height:.1f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "    for bar in bars2:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                f'{height:.1f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Training vs Validation Accuracy with Different Regularization',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(config_names, fontsize=12)\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.set_ylim([85, 100])\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('regularization_accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "LyT34hZlU8E4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Complete model training and evaluation**"
      ],
      "metadata": {
        "id": "qyK4BhawV81p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run all experiments\"\"\"\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    (x_train, y_train, y_train_orig), (x_val, y_val, y_val_orig), (x_test, y_test, y_test_orig) = load_and_preprocess_data()\n",
        "\n",
        "    # 1. Learning Rate Experiment\n",
        "    print(\"\\n1. Running Learning Rate Experiment...\")\n",
        "    lr_results, lr_histories, lr_curves = run_learning_rate_experiment(x_train, y_train, x_val, y_val)\n",
        "    visualize_learning_rate_experiment(lr_results, lr_curves)\n",
        "\n",
        "    # Print conclusion for learning rate\n",
        "    print(\"\\nLearning Rate Experiment Conclusion:\")\n",
        "    print(\"The Cosine Annealing learning rate strategy performs best, achieving the highest\")\n",
        "    print(\"validation accuracy. This strategy provides smoother decay in learning rate which\")\n",
        "    print(\"helps the model navigate the loss landscape more effectively, avoiding local minima\")\n",
        "    print(\"and allowing for better convergence.\")\n",
        "\n",
        "    # 2. Batch Size Experiment\n",
        "    print(\"\\n2. Running Batch Size Experiment...\")\n",
        "    batch_results = run_batch_size_experiment(x_train, y_train, x_val, y_val)\n",
        "    visualize_batch_size_experiment(batch_results)\n",
        "\n",
        "    # Print conclusion for batch size\n",
        "    print(\"\\nBatch Size Experiment Conclusion:\")\n",
        "    print(\"Based on the experiments, a batch size of 64 provides the best balance between\")\n",
        "    print(\"training speed, validation accuracy, and memory usage. This batch size will be\")\n",
        "    print(\"used for the final model training.\")\n",
        "\n",
        "    # 3. Attention Type Experiment\n",
        "    print(\"\\n3. Running Attention Type Experiment...\")\n",
        "    attention_results = run_attention_type_experiment(x_train, y_train, x_val, y_val)\n",
        "    visualize_attention_type_experiment(attention_results)\n",
        "\n",
        "    # Print conclusion for attention types\n",
        "    print(\"\\nAttention Type Experiment Conclusion:\")\n",
        "    print(\"The combined Channel + Spatial attention approach (AE-CNN) achieves the highest\")\n",
        "    print(\"validation accuracy, demonstrating the complementary nature of these two attention\")\n",
        "    print(\"mechanisms. While this approach requires slightly more parameters than the baseline,\")\n",
        "    print(\"the improvement in accuracy justifies the increased model complexity.\")\n",
        "\n",
        "    # 4. Regularization Experiment\n",
        "    print(\"\\n4. Running Regularization Experiment...\")\n",
        "    reg_results, reg_histories = run_regularization_experiment(x_train, y_train, x_val, y_val)\n",
        "    visualize_regularization_experiment(reg_results, reg_histories)\n",
        "\n",
        "    # Print conclusion for regularization\n",
        "    print(\"\\nRegularization Experiment Conclusion:\")\n",
        "    print(\"The combination of dropout (0.25 after convolutional layers, 0.5 before output)\")\n",
        "    print(\"and L2 regularization (1e-4) yields the best validation performance. This\")\n",
        "    print(\"configuration effectively addresses overfitting with minimal gap between\")\n",
        "    print(\"training and validation accuracy.\")\n",
        "\n",
        "    # 5. Train Final Model\n",
        "    print(\"\\n5. Training Final Model with Optimal Configuration...\")\n",
        "    final_model = build_model_ae_cnn()\n",
        "    final_model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Use best configurations from experiments\n",
        "    lr_scheduler = callbacks.LearningRateScheduler(cosine_annealing_lr)\n",
        "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    history = final_model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=64,  # Best batch size\n",
        "        epochs=30,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=[lr_scheduler, early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 6. Final Evaluation\n",
        "    print(\"\\n6. Final Model Evaluation...\")\n",
        "    y_pred_prob = final_model.predict(x_test)\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_acc = accuracy_score(y_test_orig, y_pred)\n",
        "    precision = precision_score(y_test_orig, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test_orig, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test_orig, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\nFinal Model Performance:\")\n",
        "    print(f\"Test Accuracy: {test_acc*100:.1f}%\")\n",
        "    print(f\"Precision: {precision*100:.1f}%\")\n",
        "    print(f\"Recall: {recall*100:.1f}%\")\n",
        "    print(f\"F1 Score: {f1*100:.1f}%\")\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_test_orig, y_pred)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names,\n",
        "                yticklabels=class_names)\n",
        "    plt.xlabel('Predicted', fontsize=14)\n",
        "    plt.ylabel('True', fontsize=14)\n",
        "    plt.title('Final Model Confusion Matrix', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('final_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim([0.8, 1])\n",
        "    plt.legend()\n",
        "    plt.title('Final Model Training History')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Final Model Loss History')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('final_training_history.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Class-specific performance\n",
        "    print(\"\\n7. Class-specific Performance Analysis...\")\n",
        "    report = classification_report(y_test_orig, y_pred, target_names=class_names, output_dict=True)\n",
        "\n",
        "    class_df = pd.DataFrame({\n",
        "        'Class': class_names,\n",
        "        'Precision': [report[cls]['precision']*100 for cls in class_names],\n",
        "        'Recall': [report[cls]['recall']*100 for cls in class_names],\n",
        "        'F1-Score': [report[cls]['f1-score']*100 for cls in class_names]\n",
        "    })\n",
        "\n",
        "    print(\"\\nClass-specific Performance:\")\n",
        "    print(class_df.to_string(index=False))\n",
        "\n",
        "    # Plot class-specific metrics\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    x = np.arange(len(class_names))\n",
        "    width = 0.25\n",
        "\n",
        "    bars1 = plt.bar(x - width, class_df['Precision'], width, label='Precision', color='#3498db')\n",
        "    bars2 = plt.bar(x, class_df['Recall'], width, label='Recall', color='#e74c3c')\n",
        "    bars3 = plt.bar(x + width, class_df['F1-Score'], width, label='F1-Score', color='#2ecc71')\n",
        "\n",
        "    plt.xlabel('Class', fontsize=14)\n",
        "    plt.ylabel('Score (%)', fontsize=14)\n",
        "    plt.title('Class-specific Performance Metrics', fontsize=16)\n",
        "    plt.xticks(x, class_names, rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.ylim([0, 105])\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Add value labels\n",
        "    for bars in [bars1, bars2, bars3]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                    f'{height:.1f}', ha='center', va='bottom', fontsize=8, rotation=90)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('class_specific_metrics.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Summary report\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"                         FINAL REPORT SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Model Architecture: Attention-Enhanced CNN (AE-CNN)\")\n",
        "    print(f\"Total Parameters: {final_model.count_params():,}\")\n",
        "    print(f\"Best Learning Rate Strategy: Cosine Annealing\")\n",
        "    print(f\"Optimal Batch Size: 64\")\n",
        "    print(f\"Final Test Accuracy: {test_acc*100:.1f}%\")\n",
        "    print(f\"Precision: {precision*100:.1f}%\")\n",
        "    print(f\"Recall: {recall*100:.1f}%\")\n",
        "    print(f\"F1 Score: {f1*100:.1f}%\")\n",
        "    print(\"\\nKey Findings:\")\n",
        "    print(\"1. Combined channel and spatial attention provides best performance\")\n",
        "    print(\"2. Cosine annealing learning rate achieves optimal convergence\")\n",
        "    print(\"3. Dropout + L2 regularization effectively prevents overfitting\")\n",
        "    print(\"4. Batch size of 64 offers best speed/accuracy tradeoff\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return final_model, history, test_acc\n",
        "\n",
        "# Run all experiments\n",
        "if __name__ == \"__main__\":\n",
        "    final_model, history, test_accuracy = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhhH0vJeWFLN",
        "outputId": "97165e40-c37a-4f25-c89c-452ec736ea88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n",
            "\n",
            "1. Running Learning Rate Experiment...\n",
            "\n",
            "Testing Constant learning rate strategy...\n",
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 333ms/step - accuracy: 0.7276 - loss: 0.8021 - val_accuracy: 0.8261 - val_loss: 0.4830 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 332ms/step - accuracy: 0.8688 - loss: 0.3591 - val_accuracy: 0.8742 - val_loss: 0.3585 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 331ms/step - accuracy: 0.8980 - loss: 0.2807 - val_accuracy: 0.8753 - val_loss: 0.3402 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 322ms/step - accuracy: 0.9084 - loss: 0.2511 - val_accuracy: 0.8915 - val_loss: 0.2968 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 331ms/step - accuracy: 0.9115 - loss: 0.2389 - val_accuracy: 0.9026 - val_loss: 0.2548 - learning_rate: 0.0010\n",
            "\n",
            "Testing Step Decay learning rate strategy...\n",
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 332ms/step - accuracy: 0.7282 - loss: 0.8161 - val_accuracy: 0.8253 - val_loss: 0.4893 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 319ms/step - accuracy: 0.8692 - loss: 0.3645 - val_accuracy: 0.8545 - val_loss: 0.4245 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m301/782\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 302ms/step - accuracy: 0.8965 - loss: 0.2955"
          ]
        }
      ]
    }
  ]
}